## Changes

- **Modified File:** `user/server.js`

1.  **Global Array for Request Logging:**
    *   A new global array named `requestLogForDebugging` was initialized:
        ```javascript
        const requestLogForDebugging = [];
        ```

2.  **Request Logging in Middleware:**
    *   The existing middleware responsible for annotating Instana spans was modified to include a new logging mechanism.
    *   For every incoming API request to the user service, a new log entry object is created and pushed into the `requestLogForDebugging` array.
    *   This log entry includes:
        *   `timestamp`: The time of the request.
        *   `path`: The request path.
        *   `method`: The HTTP method of the request.
        *   `headersSample`: A substring (first 200 characters) of the stringified request headers.
        *   `dummyData`: A `Buffer.alloc(512)` which adds 0.5KB of data to each log entry. This is intended to make the memory accumulation more noticeable.
    *   A conditional debug log message `req.log.debug({ message: "Internal request log growing", size: requestLogForDebugging.length });` was added to log the size of the array every 100 entries, though the default service log level is 'info'.

    ```javascript
    // --- ADDED START ---
    const logEntry = {
        timestamp: Date.now(),
        path: req.path,
        method: req.method,
        headersSample: JSON.stringify(req.headers).substring(0, 200), // Storing part of headers
        // Add a bit more data to make the leak noticeable and somewhat realistic for "debug" data
        dummyData: Buffer.alloc(512) // 0.5 KB per request, uninitialized buffer
    };
    requestLogForDebugging.push(logEntry);

    // Log growth at debug level, so it's not noisy by default but discoverable
    // The default pino log level in this service is 'info'.
    if (requestLogForDebugging.length % 100 === 0 && requestLogForDebugging.length > 0) {
        req.log.debug({ message: "Internal request log growing", size: requestLogForDebugging.length });
    }
    // --- ADDED END ---
    ```

## How Changes Affect Application

The introduced changes will cause a **memory leak** in the `user` microservice.

- With every API request handled by the `user` service, a new entry (including a 0.5KB buffer) is added to the global `requestLogForDebugging` array.
- This array is never cleared or capped in size. As a result, its memory footprint will grow continuously as long as the service processes requests.
- Under sustained load, such as that generated by the `load-gen/robot-shop.py` testing script, the `user` service will consume an increasing amount of memory over time.
- Eventually, the Node.js process for the `user` service will exhaust its available heap memory.

**Observable Symptoms will include:**
- A steady increase in the memory utilization metric for the `user` service container/pod.
- Potential "JavaScript heap out of memory" errors or similar memory-related fatal errors appearing in the `user` service logs.
- Increased request latency for the `user` service as memory pressure builds and garbage collection becomes less effective.
- Ultimately, the `user` service may become unresponsive or crash, leading to service unavailability for user-related operations (login, registration, unique ID generation).

This behavior is intentionally introduced for an incident response training exercise to simulate a real-world memory leak scenario.